op1: SchedulerNode(ComputedBuffer)
op1.writes = [MemoryDep('buf1', c0, {c0: 3})]
op1.unmet_dependencies = []
op1.met_dependencies = 
    [   MemoryDep('primals_1', ModularIndexing(c0, 1, 20480), {c0: 20481}),
        MemoryDep('primals_2', ModularIndexing(c0, 1, 20480), {c0: 20481})]
op1.outputs = [
    buf1: ComputedBuffer
    buf1.layout = FixedLayout('cuda:0', torch.float32, size=[3], stride=[1])
    buf1.users = [NodeUser(node=SchedulerNode(name='op2'), can_inplace=False, is_weak=False)]
]
op1.group.device = cuda:0
op1.group.iteration = (3, 6827)
op1.sizes = ([3], [6827])
primals_1_layout = FixedLayout('cuda:0', torch.float32, size=[20, 1, 32, 32], stride=[1024, 1024, 32, 1])
primals_2_layout = FixedLayout('cuda:0', torch.float32, size=[20, 1, 32, 32], stride=[1024, 1024, 32, 1])
buf1_layout = FixedLayout('cuda:0', torch.float32, size=[3], stride=[1])
class op1_loop_body:
    var_ranges = {p0: 3, p1: 6827}
    index0 = 6827*p0 + p1
    index1 = ModularIndexing(6827*p0 + p1, 1, 20480)
    index2 = p0
    def body(self, ops):
        get_index = self.get_index('index0')
        index_expr = ops.index_expr(get_index, torch.int32)
        constant = ops.constant(20480, torch.int32)
        lt = ops.lt(index_expr, constant)
        masked_subblock1 = self.masked_subblock1(lt, 0)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', masked_subblock1)
        get_index_1 = self.get_index('index2')
        store_reduction = ops.store_reduction('buf1', get_index_1, reduction)
        return None
    def masked_subblock1(self, ops):
        get_index = self.get_index('index1')
        load = ops.load('primals_1', get_index)
        get_index_1 = self.get_index('index1')
        load_1 = ops.load('primals_2', get_index_1)
        mul = ops.mul(load, load_1)
        return mul


op2: SchedulerNode(ComputedBuffer)
op2.writes = [MemoryDep('buf2', 0, {})]
op2.unmet_dependencies = [MemoryDep('buf1', c0, {c0: 3})]
op2.met_dependencies = []
op2.outputs = [
    buf2: ComputedBuffer
    buf2.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf2.users = [NodeUser(node=SchedulerNode(name='op3'), can_inplace=True, is_weak=False)]
]
op2.group.device = cuda:0
op2.group.iteration = (1, 3)
op2.sizes = ([], [3])
buf1_layout = FixedLayout('cuda:0', torch.float32, size=[3], stride=[1])
buf2_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op2_loop_body:
    var_ranges = {p0: 3}
    index0 = p0
    index1 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf1', get_index)
        reduction = ops.reduction(torch.float32, torch.float32, 'sum', load)
        get_index_1 = self.get_index('index1')
        store_reduction = ops.store_reduction('buf2', get_index_1, reduction)
        return None


op3: SchedulerNode(ComputedBuffer)
op3.writes = [MemoryDep('buf3', 0, {})]
op3.unmet_dependencies = [MemoryDep('buf2', 0, {})]
op3.met_dependencies = []
op3.outputs = [
    buf3: ComputedBuffer
    buf3.layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
    buf3.users = [NodeUser(node=OUTPUT, can_inplace=False, is_weak=False)]
]
op3.group.device = cuda:0
op3.group.iteration = (1, 1)
op3.sizes = ([], [])
buf2_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
buf3_layout = FixedLayout('cuda:0', torch.float32, size=[], stride=[])
class op3_loop_body:
    var_ranges = {}
    index0 = 0
    def body(self, ops):
        get_index = self.get_index('index0')
        load = ops.load('buf2', get_index)
        constant = ops.constant(20480.0, torch.float32)
        truediv = ops.truediv(load, constant)
        get_index_1 = self.get_index('index0')
        store = ops.store('buf3', get_index_1, truediv, None)
        return store


